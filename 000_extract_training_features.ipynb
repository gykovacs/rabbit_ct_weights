{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation by registration and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executables being used: /usr/bin/elastix /usr/bin/transformix\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import maweight\n",
    "import pickle\n",
    "import logging\n",
    "import tqdm\n",
    "\n",
    "from config import manually_segmented_path, dissected_path\n",
    "from config import output_path, mld_features_path, hinds_features_path \n",
    "from config import save_registered_images\n",
    "from config import bin_width, threshold\n",
    "\n",
    "LIMIT=None\n",
    "\n",
    "# setting the logging format\n",
    "FORMAT = '%(asctime)-15s %(clientip)s %(user)-8s %(message)s'\n",
    "logging.basicConfig(format=FORMAT, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discovering files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "manually_segmented_files= sorted(glob.glob(os.path.join(manually_segmented_path, '*.nii')))\n",
    "manually_segmented_images= [f for f in manually_segmented_files if not 'hinds' in \n",
    "                            f.split(os.sep)[-1] and not 'mld' in f.split(os.sep)[-1]]\n",
    "manually_segmented_hinds= [f for f in manually_segmented_files if 'hinds' in f]\n",
    "manually_segmented_mlds= [f for f in manually_segmented_files if 'mld' in f]\n",
    "\n",
    "if LIMIT is None:\n",
    "    dissected_images= sorted(glob.glob(os.path.join(dissected_path, '*.nii')))\n",
    "else:\n",
    "    dissected_images= sorted(glob.glob(os.path.join(dissected_path, '*.nii')))[:LIMIT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation by Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [8:59:15<00:00, 190.33s/it]\n"
     ]
    }
   ],
   "source": [
    "for d in tqdm.tqdm(dissected_images):\n",
    "    for (i, h, m) in zip(manually_segmented_images, manually_segmented_hinds, manually_segmented_mlds):\n",
    "        output_mld= os.path.join(output_path, d.split(os.sep)[-1] + '-' + m.split(os.sep)[-1])\n",
    "        output_hinds= os.path.join(output_path, d.split(os.sep)[-1] + '-' + h.split(os.sep)[-1])\n",
    "        if save_registered_images:\n",
    "            output_registered= os.path.join(output_path, d.split(os.sep)[-1] + '-' + i.split(os.sep)[-1])\n",
    "        else:\n",
    "            output_registered= None\n",
    "        \n",
    "        if (not os.path.isfile(output_mld) or not os.path.isfile(output_hinds) or \n",
    "            (save_registered_images and not os.path.isfile(output_registered))):\n",
    "            maweight.register_and_transform(i, d, [m, h], [output_mld, output_hinds], \n",
    "                                          registered_image_path= output_registered, verbose= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dissected_images, manually_segmented_targets):\n",
    "    dataframes= []\n",
    "    for d in tqdm.tqdm(dissected_images):\n",
    "        fitted_masks= []\n",
    "        for m in manually_segmented_targets:\n",
    "            output_mld= os.path.join(output_path, d.split(os.sep)[-1] + '-' + m.split(os.sep)[-1])\n",
    "            fitted_masks.append(output_mld)\n",
    "\n",
    "        labels= [f.split(os.sep)[-1][14:] for f in fitted_masks]\n",
    "\n",
    "        dataframes.append(maweight.extract_features_3d(d, fitted_masks, labels, bins=[i*bin_width for i in range(int(200/bin_width)+1)], thresholds=[threshold]))\n",
    "    dataframes= pd.concat(dataframes, axis=0)\n",
    "    dataframes['filename']= dissected_images\n",
    "    \n",
    "    return dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [18:46<00:00,  6.63s/it]\n"
     ]
    }
   ],
   "source": [
    "mld_features= extract_features(dissected_images, manually_segmented_mlds)\n",
    "mld_features.to_csv(mld_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170/170 [17:54<00:00,  6.32s/it]\n"
     ]
    }
   ],
   "source": [
    "hinds_features= extract_features(dissected_images, manually_segmented_hinds)\n",
    "hinds_features.to_csv(hinds_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num-203a-mld.nii-0.500000', 'sum-203a-mld.nii-0.500000',\n",
       "       'mean-203a-mld.nii-0.500000', 'std-203a-mld.nii-0.500000',\n",
       "       'skew-203a-mld.nii-0.500000', 'kurt-203a-mld.nii-0.500000',\n",
       "       'hist-0-203a-mld.nii-0.500000', 'hist-1-203a-mld.nii-0.500000',\n",
       "       'hist-2-203a-mld.nii-0.500000', 'hist-3-203a-mld.nii-0.500000',\n",
       "       ...\n",
       "       'hist-11-0.500000-mean_mask', 'hist-12-0.500000-mean_mask',\n",
       "       'hist-13-0.500000-mean_mask', 'hist-14-0.500000-mean_mask',\n",
       "       'hist-15-0.500000-mean_mask', 'hist-16-0.500000-mean_mask',\n",
       "       'hist-17-0.500000-mean_mask', 'hist-18-0.500000-mean_mask',\n",
       "       'hist-19-0.500000-mean_mask', 'filename'],\n",
       "      dtype='object', length=157)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mld_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mld_features.to_csv(mld_features_path, index=False)\n",
    "hinds_features.to_csv(hinds_features_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('maweight': conda)",
   "metadata": {
    "interpreter": {
     "hash": "44c6487f2806288468fc38a77d75a796f16db53972b2c852a298fb4c21f6bdc6"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
